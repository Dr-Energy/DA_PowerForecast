{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #기본 모듈\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "#전처리 모듈\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM 모델 클래스 정의(summer)\n",
    "class LSTM_summer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(LSTM_summer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size_s = 15\n",
    "hidden_size_ = 100  # 은닉 상태 차원(100,150)\n",
    "learning_rate = 0.0005 # 학습률(0.0005)\n",
    "num_layers = 2  # LSTM 층의 수\n",
    "output_size = 1  # 출력 차원\n",
    "num_epochs = 100  # 학습 횟수\n",
    "batch_size = 64  # 배치 크기\n",
    "save_interval = 10  # 모델을 저장할 epoch 간격\n",
    "dropout_prob = 0.3  # 드롭아웃 비율\n",
    "save_dir = '../MODELS'  # 모델 저장 경로\n",
    "early_stopping_patience = 10  # 조기 종료를 위한 인내 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM 모델 클래스 정의(non_summer)\n",
    "class LSTMmodel_non_summer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(LSTMmodel_non_summer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "#하이퍼파라미터 설정\n",
    "input_size = 14\n",
    "hidden_size = 100  # 은닉 상태 차원(100,150)\n",
    "learning_rate = 0.0005 # 학습률(0.0005)\n",
    "num_layers = 2  # LSTM 층의 수\n",
    "output_size = 1  # 출력 차원\n",
    "num_epochs = 100  # 학습 횟수\n",
    "batch_size = 64  # 배치 크기\n",
    "save_interval = 10  # 모델을 저장할 epoch 간격\n",
    "dropout_prob = 0.3  # 드롭아웃 비율\n",
    "save_dir = '../MODELS'  # 모델 저장 경로\n",
    "early_stopping_patience = 10  # 조기 종료를 위한 인내 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 디바이스 설정\n",
    "LSTMmodel_summer = LSTM_summer(input_size_s, hidden_size, num_layers, output_size, dropout_prob) \n",
    "LSTMmodel_non_summer = LSTMmodel_non_summer(input_size, hidden_size, num_layers, output_size, dropout_prob) \n",
    "\n",
    "#모델 저장 경로\n",
    "load_path_summer = '../MODELS/summer_hidden100_lr0.0005/LSTM_summer.pth'\n",
    "load_path_non_summer = '../MODELS/non_summer_hidden100_lr0.0005/LSTM_non_summer.pth'\n",
    "\n",
    "# GPU 사용 여부 확인 및 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# summer model load\n",
    "LSTMmodel_summer.load_state_dict(torch.load(load_path_summer, map_location=device))\n",
    "LSTMmodel_summer\n",
    "LSTMmodel_summer.eval()  # 모델을 평가 모드로 전환\n",
    "\n",
    "# non_summer model load\n",
    "LSTMmodel_non_summer.load_state_dict(torch.load(load_path_non_summer, map_location=device))\n",
    "LSTMmodel_non_summer\n",
    "LSTMmodel_non_summer.eval()  # 모델을 평가 모드로 전환\n",
    "\n",
    "print(f'Model loaded from {load_path_summer}')\n",
    "print(f'Model loaded from {load_path_non_summer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.시간 파생변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_time(data):\n",
    "    data['TM'] = pd.to_datetime(data['TM']) #datetime 형식으로 변환\n",
    "\n",
    "    #시간 순으로 데이터 정렬\n",
    "    data = data.sort_values(by='TM')\n",
    "\n",
    "    data['YY'] = data['TM'].dt.year #년을 새로운 열로 추가\n",
    "    data['MM'] = data['TM'].dt.month #월을 새로운 열로 추가\n",
    "    data['DD'] = data['TM'].dt.day #일을 새로운 열로 추가\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.결측치 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillnan(data):\n",
    "    #결측치(-99)를 nan으로 수정\n",
    "    data.replace(-99, np.nan, inplace=True) \n",
    "\n",
    "    #시계열 데이터를 인덱스로 지정\n",
    "    data.set_index('TM', inplace=True)\n",
    "\n",
    "    #선형보간법으로 결측치 처리\n",
    "    data.interpolate(method='time', inplace=True)\n",
    "\n",
    "    #인덱스 되돌리기\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.계절 레이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_season_label(data):\n",
    "    input = data.copy()\n",
    "\n",
    "    #7월과 8월일 때 1, 그렇지 않을 때 0로 계절 레이블 생성\n",
    "    input['season_label'] = input['MM'].isin([7, 8]).astype(int)\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.MAVG Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_decomposition(data, window=24):\n",
    "    input = data.copy()\n",
    "\n",
    "    # 결과를 저장할 열 추가\n",
    "    input['trend_s'] = 0.0\n",
    "    input['seasonal_s'] = 0.0\n",
    "    input['residual_s'] = 0.0\n",
    "\n",
    "    # 고유한 시즌 라벨에 대해 반복\n",
    "    for label in input['season_label'].unique():\n",
    "        subset = input[input['season_label'] == label].copy()\n",
    "        \n",
    "        #이동 평균을 이용한 추세 추정\n",
    "        subset['trend_s'] = subset['elect'].rolling(window=window, center=True).mean()\n",
    "        subset['trend_s'] = subset['trend_s'].ffill()\n",
    "        subset['trend_s'] = subset['trend_s'].bfill()  #앞뒤 NaN 값 채우기\n",
    "        \n",
    "        #계절성 추정 (원래 값에서 추세를 뺀 값)\n",
    "        subset['seasonal_s'] = subset['elect'] - subset['trend_s']\n",
    "        subset['seasonal_s'] = subset['seasonal_s'].ffill()\n",
    "        subset['seasonal_s'] = subset['seasonal_s'].bfill()  #앞뒤 NaN 값 채우기\n",
    "        \n",
    "        #잔차 계산 (원래 값에서 추세와 계절성을 뺀 값)\n",
    "        subset['residual_s'] = subset['elect'] - subset['trend_s'] - subset['seasonal_s']\n",
    "        subset['residual_s'] = subset['residual_s'].ffill()\n",
    "        subset['residual_s'] = subset['residual_s'].bfill()  #앞뒤 NaN 값 채우기\n",
    "        \n",
    "        #원래 데이터 프레임에 결과 할당\n",
    "        input.loc[subset.index, 'trend_s'] = subset['trend_s']\n",
    "        input.loc[subset.index, 'seasonal_s'] = subset['seasonal_s']\n",
    "        input.loc[subset.index, 'residual_s'] = subset['residual_s']\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.차분값 파생변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_data(data):\n",
    "    input = data.copy()\n",
    "\n",
    "    # 전력 차분\n",
    "    input['difference1_e'] = input['elect'].diff()  \n",
    "    input['difference2_e'] = input['elect'].diff(2)  \n",
    "    input['difference3_e'] = input['elect'].diff(3) \n",
    "\n",
    "    # 습도 차분\n",
    "    input['difference1_h'] = input['nph_hm'].diff()  \n",
    "    input['difference2_h'] = input['nph_hm'].diff(2)  \n",
    "    input['difference3_h'] = input['nph_hm'].diff(3)  \n",
    "\n",
    "    # 기온 차분\n",
    "    input['difference1_t'] = input['nph_ta'].diff() \n",
    "    input['difference2_t'] = input['nph_ta'].diff(2) \n",
    "    input['difference3_t'] = input['nph_ta'].diff(3) \n",
    "\n",
    "    # 앞쪽 채움 처리 후 nan 값이 남아있을 경우 뒤쪽 채움으로 처리\n",
    "    input['difference1_e'] = input['difference1_e'].ffill().bfill()\n",
    "    input['difference2_e'] = input['difference2_e'].ffill().bfill()\n",
    "    input['difference3_e'] = input['difference3_e'].ffill().bfill()\n",
    "\n",
    "    input['difference1_h'] = input['difference1_h'].ffill().bfill()\n",
    "    input['difference2_h'] = input['difference2_h'].ffill().bfill()\n",
    "    input['difference3_h'] = input['difference3_h'].ffill().bfill()\n",
    "    \n",
    "    input['difference1_t'] = input['difference1_t'].ffill().bfill()\n",
    "    input['difference2_t'] = input['difference2_t'].ffill().bfill()\n",
    "    input['difference3_t'] = input['difference3_t'].ffill().bfill()\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Scailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scailing\n",
    "def scailing_data(data, selected_features):\n",
    "    input = data.copy()\n",
    "\n",
    "    #스케일러 초기화\n",
    "    scaler_R = RobustScaler()\n",
    "\n",
    "    #스케일링이 필요한 컬럼 목록\n",
    "    S_columns = ['NUM', 'YY', 'MM', 'DD', 'HH24', 'weekday', 'week_name', 'STN',\n",
    "                'nph_ta', 'nph_hm', 'nph_ws_10m', 'nph_rn_60m', 'nph_ta_chi', 'elect']\n",
    "\n",
    "\n",
    "    #스케일링하는 데이터와 하지 않는 컬럼 분리\n",
    "    scaling_features = [feature for feature in selected_features if feature in S_columns]\n",
    "    non_scaling_features = [feature for feature in selected_features if feature not in S_columns]\n",
    "\n",
    "    #필요한 데이터만 추출\n",
    "    scale_data = input[scaling_features].copy()\n",
    "    non_scale_data = input[non_scaling_features].copy()\n",
    "\n",
    "    #스케일러 적용\n",
    "    scaled_R = scaler_R.fit_transform(scale_data)\n",
    "\n",
    "    #결과를 다시 DataFrame으로 변환\n",
    "    scaled_R = pd.DataFrame(scaled_R, columns=scale_data.columns)\n",
    "\n",
    "    final_data = pd.concat([scaled_R, non_scale_data.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.시퀀스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(data):\n",
    "    input = data.copy()\n",
    "\n",
    "    seq_length=24\n",
    "    num_sequences = len(input) - seq_length + 1\n",
    "\n",
    "    #Numpy 배열을 미리 할당하여 메모리 사용을 최적화\n",
    "    vs = np.zeros((num_sequences, seq_length, input.shape[1]))\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        vs[i] = input.iloc[i:i+seq_length].values\n",
    "\n",
    "    #가장 마지막 24시간 시퀀스를 선택\n",
    "    recent_sequence = vs[-1] \n",
    "    \n",
    "    return recent_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTensor(vs):\n",
    "    #입력값이 ndarray인지 확인\n",
    "    if not isinstance(vs, np.ndarray):\n",
    "        raise ValueError(\"Input data must be a numpy ndarray\")\n",
    "    \n",
    "    # 데이터 복사를 피하고, float32로 변환\n",
    "    tensor = torch.from_numpy(vs).float().unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input):\n",
    "    input = input.to(device)  # 입력 데이터를 GPU로 이동\n",
    "    model = model.to(device)  # 모델을 GPU로 이동\n",
    "    with torch.no_grad():  # 예측 시에는 역전파를 사용하지 않도록 설정\n",
    "        prediction = model(input)\n",
    "    return prediction.cpu().numpy().flatten()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data, start_date, end_date, pred_time):\n",
    "    #시간 파생변수\n",
    "    time_data = preprocess_time(data)\n",
    "\n",
    "    #3개월치 데이터 자르기\n",
    "    mask = (time_data['TM'] >= start_date) & (time_data['TM'] <= end_date)\n",
    "    filtered_data = time_data.loc[mask].copy()\n",
    "\n",
    "    #예측할 시간의 기상데이터(예측 데이터)\n",
    "    pred_data = data.loc[data['TM'] == pred_time].copy()\n",
    "\n",
    "    #모델과 피처값 선정하기\n",
    "    pred_data = preprocess_time(pred_data)\n",
    "    if (pred_data['MM'].isin([7, 8])).any():\n",
    "        model = LSTMmodel_summer\n",
    "        features = ['difference3_t', 'MM', 'nph_ta', 'DD', 'difference1_e', 'week_name', 'trend_s', 'difference2_e',\n",
    "                    'difference3_h', 'HH24', 'difference2_h', 'seasonal_s', 'nph_ta_chi', 'residual_s', 'elect']\n",
    "        \n",
    "    else:\n",
    "        model = LSTMmodel_non_summer\n",
    "        features = ['difference3_t', 'MM', 'nph_ta', 'DD', 'week_name', 'trend_s', 'difference2_e',\n",
    "                    'difference3_h', 'HH24', 'difference2_h', 'seasonal_s', 'nph_ta_chi', 'residual_s', 'elect']\n",
    "\n",
    "    #결측치 처리\n",
    "    fillnan_data = fillnan(filtered_data)\n",
    "\n",
    "    #계절 레이블 생성\n",
    "    seasonal_data = create_season_label(fillnan_data)\n",
    "\n",
    "    #MAVG decomposition\n",
    "    mavg_data = moving_average_decomposition(seasonal_data)\n",
    "\n",
    "    #차분값 파생변수\n",
    "    diffed_data = diff_data(mavg_data)\n",
    "\n",
    "    #데이터 스케일링\n",
    "    scaled_data = scailing_data(diffed_data, features)\n",
    "\n",
    "    #sequence 생성\n",
    "    sequence_data = create_sequence(scaled_data)\n",
    "\n",
    "    #tensor 변환\n",
    "    tensor_data = toTensor(sequence_data)\n",
    "\n",
    "    #예측하기\n",
    "    prediction = predict(model, tensor_data)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로드(2022년 3개월 데이터를 2023년 데이터와 합침)\n",
    "data = pd.read_csv(\"../Data/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #시작 날짜와 끝 날짜 설정\n",
    "    start_date = '2022-10-01 01:00:00'\n",
    "    end_date  = '2024-01-01 00:00:00'\n",
    "\n",
    "    #1시간 단위로 날짜 범위 생성\n",
    "    times = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "\n",
    "    #시작 시간과 끝 시간을 3개월 간격으로 유지\n",
    "    for i in tqdm(range(len(times) - 1), desc=\"Processing time intervals\"):\n",
    "        current_start_date = times[i].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        current_end_date = (pd.to_datetime(current_start_date) + pd.DateOffset(months=3) - pd.Timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(f'Processing from {current_start_date} to {current_end_date}')\n",
    "        \n",
    "        pred_time = (pd.to_datetime(current_end_date) + pd.Timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        prediction = process(data, current_start_date, current_end_date, pred_time) #예측값을 prediction에 저장\n",
    "        prediction = np.float64(prediction).round(2)  #float64로 변환 및 소수점 2자리로 반올림\n",
    "        data.loc[data['TM'] == pred_time, 'elect'] = prediction #prediction을 data에 저장\n",
    "        \n",
    "    print('Processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 데이터만 잘라내기\n",
    "pred_data = data[(data['TM'] >= '2023-01-01 01:00:00') & (data['TM'] <= '2024-01-01 00:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일로 저장하기\n",
    "pred_data.to_csv('240409.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
