{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rE5RCZW5om3a"},"outputs":[],"source":["#기본 모듈\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","#전처리 모듈\n","from sklearn.preprocessing import RobustScaler\n","\n","#모델 평가\n","from sklearn.model_selection import TimeSeriesSplit\n","from scipy.stats import pearsonr\n","\n","#Pytorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.optim as optim\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1718757812049,"user":{"displayName":"이세련","userId":"04148692410157842841"},"user_tz":-540},"id":"ghWnnujoom3c","outputId":"70ddd99e-2057-4162-ebc5-c254fee644f6"},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":19119,"status":"ok","timestamp":1718757835170,"user":{"displayName":"이세련","userId":"04148692410157842841"},"user_tz":-540},"id":"RWmyYwaQom3d","outputId":"95341ced-3f4c-4987-a7a3-bbeb10451f05"},"outputs":[],"source":["#데이터 적재\n","data = pd.read_csv(\"../Data/electric_train.csv\")\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#컬럼명 변경\n","def change_column_name(data):\n","    data.rename(columns={'electric_train.tm' : 'TM',\n","                    'electric_train.num' : 'NUM',\n","                     'electric_train.hh24' : 'HH24',\n","                     'electric_train.stn' : 'STN',\n","                     'electric_train.sum_load' : 'sum_load',\n","                     'electric_train.nph_ta' : 'nph_ta',\n","                     'electric_train.nph_hm' : 'nph_hm',\n","                     'electric_train.nph_ws_10m' : 'nph_ws_10m',\n","                     'electric_train.nph_rn_60m' : 'nph_rn_60m',\n","                     'electric_train.nph_ta_chi' : 'nph_ta_chi',\n","                     'electric_train.weekday' : 'weekday',\n","                     'electric_train.week_name' : 'week_name',\n","                     'electric_train.elec' : 'elect'}, inplace=True)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#시간 파생변수\n","def preprocess_time(data):\n","    data['TM'] = pd.to_datetime(data['TM']) #datetime 형식으로 변환\n","    \n","    #시간 순으로 데이터 정렬\n","    data = data.sort_values(by='TM')\n","\n","    data['YY'] = data['TM'].dt.year #년을 새로운 열로 추가\n","    data['MM'] = data['TM'].dt.month #월을 새로운 열로 추가\n","    data['DD'] = data['TM'].dt.day #일을 새로운 열로 추가\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#결측치 처리하기\n","def fillnan(data):\n","    #결측치를 nan으로 수정\n","    data.replace(-99, np.nan, inplace=True) \n","\n","    #시계열 데이터를 인덱스로 지정\n","    data.set_index('TM', inplace=True)\n","\n","    #선형보간법으로 결측치 처리\n","    data.interpolate(method='time', inplace=True)\n","\n","    #인덱스 되돌리기\n","    data.reset_index(drop=True, inplace=True)\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#계절 레이블 생성\n","def create_season_label(data):\n","    input = data.copy()\n","\n","    #7월과 8월일 때 1, 그렇지 않을 때 0로 계절 레이블 생성\n","    input['season_label'] = input['MM'].isin([7, 8]).astype(int)\n","\n","    return input"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def moving_average_decomposition(data, window=24):\n","    input = data.copy()\n","\n","    # 결과를 저장할 열 추가\n","    input['trend_s'] = 0.0\n","    input['seasonal_s'] = 0.0\n","    input['residual_s'] = 0.0\n","\n","    # 고유한 시즌 라벨에 대해 반복\n","    for label in input['season_label'].unique():\n","        subset = input[input['season_label'] == label].copy()\n","        \n","        # 이동 평균을 이용한 추세 추정\n","        subset['trend_s'] = subset['elect'].rolling(window=window, center=True).mean()\n","        subset['trend_s'] = subset['trend_s'].ffill()\n","        subset['trend_s'] = subset['trend_s'].bfill()  # 앞뒤 NaN 값 채우기\n","        \n","        # 계절성 추정 (원래 값에서 추세를 뺀 값)\n","        subset['seasonal_s'] = subset['elect'] - subset['trend_s']\n","        subset['seasonal_s'] = subset['seasonal_s'].ffill()\n","        subset['seasonal_s'] = subset['seasonal_s'].bfill()  # 앞뒤 NaN 값 채우기\n","        \n","        # 잔차 계산 (원래 값에서 추세와 계절성을 뺀 값)\n","        subset['residual_s'] = subset['elect'] - subset['trend_s'] - subset['seasonal_s']\n","        subset['residual_s'] = subset['residual_s'].ffill()\n","        subset['residual_s'] = subset['residual_s'].bfill()  # 앞뒤 NaN 값 채우기\n","        \n","        # 원래 데이터 프레임에 결과 할당\n","        input.loc[subset.index, 'trend_s'] = subset['trend_s']\n","        input.loc[subset.index, 'seasonal_s'] = subset['seasonal_s']\n","        input.loc[subset.index, 'residual_s'] = subset['residual_s']\n","\n","    return input"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#차분값 파생변수\n","def diff_data(data):\n","    #전력 차분\n","    data['difference1_e'] = data['elect'].diff() #1차 차분\n","    data['difference2_e'] = data['elect'].diff(2) #2차 차분\n","    data['difference3_e'] = data['elect'].diff(3) #3차 차분\n","\n","    #습도 차분\n","    data['difference1_h'] = data['nph_hm'].diff() #1차 차분\n","    data['difference2_h'] = data['nph_hm'].diff(2) #2차 차분\n","    data['difference3_h'] = data['nph_hm'].diff(3) #3차 차분\n","\n","    #기온 차분\n","    data['difference1_t'] = data['nph_ta'].diff() \n","    data['difference2_t'] = data['nph_ta'].diff(2) \n","    data['difference3_t'] = data['nph_ta'].diff(3) \n","\n","    #앞쪽 채움 처리 후 nan 값이 남아있을 경우 뒤쪽 채움으로 처리\n","    data['difference1_e'] = data['difference1_e'].ffill().bfill()\n","    data['difference2_e'] = data['difference2_e'].ffill().bfill()\n","    data['difference3_e'] = data['difference3_e'].ffill().bfill() \n","\n","    data['difference1_h'] = data['difference1_h'].ffill().bfill()\n","    data['difference2_h'] = data['difference2_h'].ffill().bfill()\n","    data['difference3_h'] = data['difference3_h'].ffill().bfill()\n","    \n","    data['difference1_t'] = data['difference1_t'].ffill().bfill()\n","    data['difference2_t'] = data['difference2_t'].ffill().bfill()\n","    data['difference3_t'] = data['difference3_t'].ffill().bfill()\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#scailing\n","def scailing_data(data, selected_features):\n","    #스케일러 초기화\n","    scaler_R = RobustScaler()\n","\n","    #스케일링이 필요한 컬럼 목록\n","    S_columns = ['NUM', 'YY', 'MM', 'DD', 'HH24', 'weekday', 'week_name', 'STN',\n","                'nph_ta', 'nph_hm', 'nph_ws_10m', 'nph_rn_60m', 'nph_ta_chi', 'elect']\n","\n","\n","    scaling_features = [feature for feature in selected_features if feature in S_columns]\n","    non_scaling_features = [feature for feature in selected_features if feature not in S_columns]\n","\n","    #필요한 데이터만 추출\n","    scale_data = data[scaling_features].copy()\n","    non_scale_data = data[non_scaling_features].copy()\n","\n","    #스케일러 적용\n","    scaled_R = scaler_R.fit_transform(scale_data)\n","\n","    #결과를 다시 DataFrame으로 변환\n","    scaled_R = pd.DataFrame(scaled_R, columns=scale_data.columns)\n","\n","    #데이터프레임 합치기\n","    final_data = pd.concat([scaled_R, non_scale_data.reset_index(drop=True)], axis=1)\n","\n","    return final_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#sequence data\n","def create_sequence(data):\n","    seq_length=24\n","    num_sequences = len(data) - seq_length + 1\n","\n","    #Numpy 배열을 미리 할당하여 메모리 사용을 최적화\n","    vs = np.zeros((num_sequences, seq_length, data.shape[1]))\n","    \n","    for i in tqdm(range(num_sequences), desc=\"Creating sequences\"):\n","        vs[i] = data.iloc[i:i+seq_length].values\n","\n","    return vs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#tensor\n","def toTensor(vs):\n","    #입력값이 ndarray인지 확인\n","    if not isinstance(vs, np.ndarray):\n","        raise ValueError(\"Input data must be a numpy ndarray\")\n","    \n","    # 데이터 복사를 피하고, float32로 변환\n","    tensor = torch.from_numpy(vs).float() \n","\n","    return tensor"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#컬럼명 바꾸기\n","data = change_column_name(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#시간 파생변수\n","time_data = preprocess_time(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#3개월치 데이터 자르기\n","start_date = '2022-10-01 01:00:00'\n","end_date = '2023-01-01 00:00:00'\n","mask = (time_data['TM'] >= start_date) & (time_data['TM'] <= end_date)\n","filtered_data = time_data.loc[mask].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#결측치 처리\n","fillnan_data = fillnan(filtered_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#계절 레이블 생성\n","seasonal_data = create_season_label(fillnan_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#MAVG decomposition\n","mavg_data = moving_average_decomposition(seasonal_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#차분값 파생변수\n","diffed_data = diff_data(mavg_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#피처값 선택\n","non_summer_features = ['difference3_t', 'MM', 'nph_ta', 'DD', 'week_name', 'trend_s', 'difference2_e',\n","                       'difference3_h', 'HH24', 'difference2_h', 'seasonal_s', 'nph_ta_chi', 'residual_s', 'elect']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#데이터 스케일링\n","scaled_data = scailing_data(diffed_data, non_summer_features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#sequence 생성\n","sequence_data = create_sequence(scaled_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#tensor 변환\n","tensor_data = toTensor(sequence_data)\n","X_tensor = tensor_data"]},{"cell_type":"markdown","metadata":{},"source":["## y 데이터"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = fillnan_data.loc[:, 'elect']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = pd.DataFrame(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["type(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_sequence = create_sequence(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_sequence_last = y_sequence[:, -1, :]  # 시퀀스의 마지막 값을 선택"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_tensor = torch.tensor(y_sequence_last, dtype=torch.float32).unsqueeze(1).squeeze(1) # y_tensor의 크기를 (n, 1)로 변환"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_tensor.size()"]},{"cell_type":"markdown","metadata":{"id":"CvECMlJeQlGp"},"source":["## TimeSeriesSplit을 이용한 교차검증"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvdGNmEMHyE1"},"outputs":[],"source":["#LSTM 모델 클래스 정의(드롭아웃 추가)\n","class LSTMmodel_non_summer(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n","        super(LSTMmodel_non_summer, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.dropout(out[:, -1, :])\n","        out = self.fc(out)\n","        return out\n","\n","#하이퍼파라미터 설정\n","input_size = len(non_summer_features)\n","hidden_size = 100  # 은닉 상태 차원(100,150)\n","learning_rate = 0.0005 # 학습률(0.0005)\n","num_layers = 2  # LSTM 층의 수\n","output_size = 1  # 출력 차원\n","num_epochs = 100  # 학습 횟수\n","batch_size = 64  # 배치 크기\n","save_interval = 10  # 모델을 저장할 epoch 간격\n","dropout_prob = 0.3  # 드롭아웃 비율\n","save_dir = '../MODELS'  # 모델 저장 경로\n","early_stopping_patience = 10  # 조기 종료를 위한 인내 횟수"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718676596177,"user":{"displayName":"이세련","userId":"04148692410157842841"},"user_tz":-540},"id":"gA_hnFsr7EKx","outputId":"9e37d80b-2ed6-40b0-8659-acaeb5f7c959"},"outputs":[],"source":["#PyTorch 코드에서 GPU 사용 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 교차 검증을 위한 TimeSeriesSplit 설정\n","tscv = TimeSeriesSplit(n_splits=5)\n","\n","print(f'\\nTraining and validating model for dataset with hidden size {hidden_size} and learning rate {learning_rate}')\n","\n","# 교차 검증\n","for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tensor)):\n","    print(f'Fold {fold+1}')\n","    X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]\n","    y_train, y_val = y_tensor[train_idx], y_tensor[val_idx]\n","\n","    # 데이터셋 생성\n","    train_dataset = TensorDataset(X_train, y_train)\n","    val_dataset = TensorDataset(X_val, y_val)\n","\n","    # 데이터 로더 생성\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # 모델 생성 및 디바이스 설정\n","    LSTMmodel = LSTMmodel_non_summer(input_size, hidden_size, num_layers, output_size, dropout_prob).to(device) # GPU로 이동\n","    criterion = nn.MSELoss()  # 손실 함수: 평균 제곱 오차\n","    optimizer = optim.Adam(LSTMmodel.parameters(), lr=learning_rate)  # 옵티마이저: Adam\n","\n","    # 상관계수를 저장할 리스트\n","    epoch_corrs = []\n","    best_val_loss = float('inf')\n","    early_stopping_counter = 0\n","\n","    # 모델 훈련\n","    for epoch in tqdm(range(num_epochs), desc=f'Fold {fold+1} Epochs'):\n","        LSTMmodel.train()\n","        train_loss = 0\n","        for inputs, labels in tqdm(train_loader, desc='Training Batches', leave=False):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # 순전파 및 손실 계산\n","            outputs = LSTMmodel(inputs)\n","            loss = criterion(outputs, labels)\n","            train_loss += loss.item()\n","\n","            # 역전파 및 가중치 업데이트\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        avg_train_loss = train_loss / len(train_loader)\n","        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}')\n","\n","        # 검증\n","        LSTMmodel.eval()\n","        val_loss = 0\n","        all_preds = []\n","        all_targets = []\n","        with torch.no_grad():\n","            for inputs, targets in tqdm(val_loader, desc='Validation Batches', leave=False):\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = LSTMmodel(inputs)\n","                loss = criterion(outputs, targets)\n","                val_loss += loss.item()\n","                all_preds.extend(outputs.cpu().numpy())\n","                all_targets.extend(targets.cpu().numpy())\n","        val_loss /= len(val_loader)\n","        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}')\n","\n","        # 상관계수 계산\n","        all_preds = np.array(all_preds).flatten()\n","        all_targets = np.array(all_targets).flatten()\n","        corr, _ = pearsonr(all_preds, all_targets)\n","        epoch_corrs.append(corr)  # 상관계수를 리스트에 추가\n","        print(f'    Epoch {epoch+1}, Pearson Correlation: {corr:.4f}')\n","\n","        # 조기 종료 체크\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stopping_counter = 0\n","            # 모델 저장\n","            save_dir_epoch = os.path.join(save_dir, f'non_summer_hidden{hidden_size}_lr{learning_rate}')\n","            os.makedirs(save_dir_epoch, exist_ok=True)\n","            save_path = os.path.join(save_dir_epoch, f'fold_{fold+1}_epoch_{epoch+1}.pth')\n","            torch.save(LSTMmodel.state_dict(), save_path)\n","            print(f'Model saved to {save_path}')\n","        else:\n","            early_stopping_counter += 1\n","            if early_stopping_counter >= early_stopping_patience:\n","                print(\"Early stopping\")\n","                break\n","\n","    # 각 fold의 에포크 상관계수 평균 계산\n","    mean_corr = np.mean(epoch_corrs)\n","    print(f'    Fold {fold+1}, Mean Pearson Correlation: {mean_corr:.4f}')\n","\n","print('All models trained and validated.')"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
